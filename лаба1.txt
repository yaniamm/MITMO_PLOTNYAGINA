Плотнягина Яна ПМИ 3-2 Вариант 13
Лабораторная работа №1: Оценка точности модели снепрерывной зависимой переменной В практических примерах ниже показано: как делить данные на выборки (обучающую и тестовую); как считать MSE: среднеквадратическую ошибку модели; как меняются MSE на тестовой и обучающей выборках с изменением гибкости (числа степеней свободы) модели. Модели: сглаживающие сплайны. Данные: сгенерированные.
Задача 1: Решение
1. зададим исходные данные и функцию и построим по ним обучающую и тестирующую выборки. Представим эти данные на графике
2. С помощью библиотеки R сплайны на обуч. выборки для DF=38 и проверим MSE значение для обучающей и тестирующей выборок. Получим сплайн на графике.
3. Подставим разные значения DF от 2 до 40 и найдем такое значение, при котором MSE значение будет наименьшим. Представим все на графике.
Результат:
1. При подборе разных значений DF определили, что для функции f(X) = 25 + 0.02 * x − 0.003 ⋅*(x − 45) + 0.00006*(x-54)^3 лучшее значение df=40
2.На графике видно, что MSE на тестовой выборке начинает уменьшаться и затем стабилизируется при увеличении количества степеней свободы. После некоторого значения, MSE на тестовой выборке начинает расти, что может свидетельствовать о переобучении модели.

Исходя из графика, можно сделать вывод, что наилучшим количеством степеней свободы для данной модели является значение около 6 или 38. Эти значения обеспечивают минимальное значение MSE на тестовой выборке и, следовательно, лучшую обобщающую способность модели.
Задача 2: Решение
1. Потворяем перебор df значение от 2 до 40 и разные значения n_all[450,400,350]. Полученные значения сохраним в фрейм и выберем для каждого n_all такое df, чтобы тестовое MSE было наименьшим. Представим график обучающих и тестовых MSE для разных df и для разных n_all, выделяя точки с наименьшим MSE.
Результат:
1.Среднеквадратичная ошибка (MSE) уменьшается с увеличением количества наблюдений в модели. Это связано с тем, что с увеличением размера выборки увеличивается точность оценок параметров модели, что в свою очередь приводит к уменьшению ошибки модели. Однако в некоторых случаях при увеличении выборки MSE может оставаться примерно постоянным или даже увеличиваться, если новые наблюдения не добавляют дополнительной информации или являются не репрезентативными.
2.Набор данных с 450 наблюдениями:

Графики MSE для обучающей и тестовой выборок показывают сходную форму. При увеличении количества степеней свободы, MSE на обеих выборках сначала снижается, затем после некоторого порога начинает расти для тестовой выборки, в то время как MSE для обучающей выборки продолжает снижаться. Это свидетельствует о переобучении модели на более сложных сплайнах, когда количество степеней свободы становится слишком высоким.
Набор данных с 400 наблюдениями:

Графики MSE для обучающей и тестовой выборок также показывают сходную форму, как и в предыдущем случае. Однако можно заметить, что MSE для обеих выборок начинает расти при более низких значениях степеней свободы по сравнению с набором данных с 450 наблюдениями. Это может быть связано с тем, что меньшее количество данных требует менее сложных моделей для адекватного предсказания.
Набор данных с 350 наблюдениями:

В данном случае графики MSE также показывают сходную форму, но уровень MSE для обеих выборок в целом выше, что может быть связано с меньшим объемом данных. При этом тренд роста MSE для тестовой выборки начинается на более низких значениях степеней свободы, чем для наборов данных с большим количеством наблюдений, что указывает на более высокий риск переобучения модели.