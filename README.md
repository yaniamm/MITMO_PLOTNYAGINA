# lab1
лабораторная 1. Машинное обучение
Плотнягина Яна ПМИ 3-2 Вариант 13

Лабораторная работа №1: Оценка точности модели снепрерывной зависимой переменной В практических примерах ниже показано: как делить данные на выборки (обучающую и тестовую); как считать MSE: среднеквадратическую ошибку модели; как меняются MSE на тестовой и обучающей выборках с изменением гибкости (числа степеней свободы) модели. Модели: сглаживающие сплайны. Данные: сгенерированные.

Задача 1: Решение
1. зададим исходные данные и функцию и построим по ним обучающую и тестирующую выборки. Представим эти данные на графике
2. С помощью библиотеки R сплайны на обуч. выборки для DF=38 и проверим MSE значение для обучающей и тестирующей выборок. Получим сплайн на графике.
3. Подставим разные значения DF от 2 до 40 и найдем такое значение, при котором MSE значение будет наименьшим. Представим все на графике.


Результат:

1. При подборе разных значений DF определили, что для функции f(X) = 25 + 0.02 * x − 0.003 ⋅*(x − 45) + 0.00006*(x-54)^3 лучшее значение df=6

2. На графике видно, что MSE на тестовой выборке начинает уменьшаться и затем стабилизируется при увеличении количества степеней свободы. После некоторого значения, MSE на тестовой выборке начинает расти, что может свидетельствовать о переобучении модели.
Исходя из графика, можно сделать вывод, что наилучшим количеством степеней свободы для данной модели является значение около 6 . Это значение обеспечивает минимальное значение MSE на тестовой выборке и, следовательно, лучшую обобщающую способность модели.


Задача 2: Решение

1. Потворяем перебор df значение от 2 до 40 и разные значения n_all[450,400,350]. Полученные значения сохраним в фрейм и выберем для каждого n_all такое df, чтобы тестовое MSE было наименьшим. Представим график обучающих и тестовых MSE для разных df и для разных n_all, выделяя точки с наименьшим MSE.


Результат:

Среднеквадратичная ошибка (MSE) уменьшается с увеличением количества наблюдений в модели. Это связано с тем, что с увеличением размера выборки увеличивается точность оценок параметров модели, что в свою очередь приводит к уменьшению ошибки модели. Однако в некоторых случаях при увеличении выборки MSE может оставаться примерно постоянным или даже увеличиваться, если новые наблюдения не добавляют дополнительной информации или являются не репрезентативными.
Важно заметить при количестве наблюдений 450 MSE_train = 0.920065	MSE_test = 1.094269

при 400 MSE_train = 1.035611 	MSE_test = 0.848195

при 350 MSE_train = 1.025383  	MSE_test = 0.750627 
то есть можно сделать вывод о том, что при уменьшении количества наблюдений  значение MSE_test уменьшается

Набор данных с 450 наблюдениями:

Графики MSE для обучающей и тестовой выборок показывают сходную форму. При увеличении количества степеней свободы, MSE на обеих выборках сначала снижается, затем после некоторого порога начинает расти для тестовой выборки, в то время как MSE для обучающей выборки продолжает снижаться. Это свидетельствует о переобучении модели на более сложных сплайнах, когда количество степеней свободы становится слишком высоким.

Набор данных с 400 наблюдениями:

Графики MSE для обучающей и тестовой выборок также показывают сходную форму, как и в предыдущем случае. Однако можно заметить, что MSE для обеих выборок начинает расти при более низких значениях степеней свободы по сравнению с набором данных с 450 наблюдениями. Это может быть связано с тем, что меньшее количество данных требует менее сложных моделей для адекватного предсказания.

Набор данных с 350 наблюдениями:

В данном случае графики MSE также показывают сходную форму, но уровень MSE для обеих выборок в целом выше, что может быть связано с меньшим объемом данных. При этом тренд роста MSE для тестовой выборки начинается на более низких значениях степеней свободы, чем для наборов данных с большим количеством наблюдений, что указывает на более высокий риск переобучения модели.

--------------------

# lab2
Лабараторная работа №2 Линейные модели. Кросс-валидация.

Вариант №13

Ниже показано:

как пользоваться инструментами предварительного анализа для поиска линейных взаимосвязей;

как строить и интерпретировать линейные модели с логарифмами;

как оценивать точность моделей с перекрёстной проверкой (LOOCV, проверка по блокам).

Модели: множественная линейная регрессия

Данные: https://raw.githubusercontent.com/ania607/ML/main/data/Carseats.csv

Зависимая переменная - Sales / продажа (в тысячах штук) в каждом магазине

Независимые переменные:

Price / цены компании на автокресла в каждом магазине;
CompPrice / цена конкурента в
каждом магазине;
ShelveLoc / качество стеллажа для размещения автокресел в каждом магазине: Плохое, Хорошее и Среднее.

Проверка осуществляется методом LOOCV

Задачи:

1 Данные своего варианта (см. таблицу ниже) разделить на выборку для построения
моделей (80%) и отложенные наблюдения (20%). Оставить в таблице только указанные в
варианте переменные. Отложенные наблюдения использовать только в задании 6

2 Провести предварительный анализ данных с помощью описательных статистик и
графиков, оценить взаимосвязь.

3 Проверить Y на нормальность. Если он распределён не по нормальному закону,
прологарифмировать и снова провести анализ взаимосвязей переменных.

4 Составить список возможных спецификаций моделей множественной регрессии (на
исходной Y и на логарифме Y ).

5 Оценить параметры моделей из списка. Оценить точность моделей методом
перекрёстной проверки, указанным в варианте. Найти самую точную из моделей для Y .
Найти самую точную из моделей для log(Y ).

6 Сделать прогноз с помощью самых точных моделей на отложенные наблюдения.
Рассчитать MSEtest вручную и выбрать одну наиболее точную модель.
Проинтерпретировать её параметры.


Задача 1:
Загружаем все необходимые для работы модули, определяем константы и загружаем входные данные. Во входных данных фильтруем только необходимые нам для работы признаки. Определяем фиктивные переменные для качественного признака и объединяем их с исходными данными. Также разделяем исходную выборку на тренировочную и тестовую.

Результат задачи 1:
Получили две выборки: тестовая и тренировочная

Задача 2:

Проведем анализ на тренировочной выборке:
1. построим гистограммы распределения и графики зависимости количественных переменных;
2. построим гистограммы распределения и графики зависимости количественных перемнных для разных значений качественной перемнной;
3. построим матрицу корреляции количественных переменных;
4. построим матрицу корреляции количественных переменных для разных значений качественной переменной.

Результаты задачи 2:

1. По гистограмме распределения "Sales" можно сделать предположение, что данные распределены нормально.

2. По графикам распределения видно, что переменная "Sales" слабо зависит от "CompPrice" и сильно обратно зависима от переменной "Price". Это подтверждается матрицей корреляции.

3. Разные значения качественной переменной "ShelveLoc" заметно влияют на среднее значения распределения переменной "Sales".

По матрицам корреляции видно, что значение переменной "ShelveLoc" == "Good" усиливает коррелированность "Price" и "Sales", а значение переменной "ShelveLoc" == "Medium" усиливает коррелированность "CompPrice" и "Sales".

Задача 3:
Проверим распределение переменной "Sales" на нормальность при помощи теста Шапиро-Уилка. Если распределение не является нормальным, проверим логарифм переменной на нормальность.

Результаты задачи 3:
Так как исходные данные обладают значениями "Sales" == 0, а также так как мы уже подтвердили нормальность переменной "Sales", логарифм переменной "Sales" далее рассматриваться не будет.

Задача 4 решение и резульаты:
в соответсвие с резульатами задачи 2 можно составить следующие линейные спецификации модели:

Sales = CompPrice + Price + Medium + Good
Sales = CompPrice + Price * Good + Medium + Good
Sales = CompPrice * Medium + Price + Medium + Good
Sales = CompPrice * Medium + Price * Good + Medium + Good

показательные модели рассматриваться не будут (в соответсвии с результатами задачи 3) 

Задача 5:
Построим модели, определенные в задании 4.

Определим параметры моделей и оценим их точность методом LOOCV.

Найдем самую точную из моделей.

Результаты задачи 5:
Мы определили, что наименьшую ошибку методом LOOCV выдает модель №1:

Sales = CompPrice + Price + Medium + Good


Задача 6:
Сделаем прогноз первой моделью на тестовые данные и оценим полученную ошибку тестирования. Оценим среднюю ошибку модели.

Построим первую модель на всех данных и проинтерпретируем ее параметры.

Результаты задачи 6:

Ошибка модели, построенной на тренировочных данных составила 21.8% от среднего значения Y

В результате построения на всех данных была получена модель:

Sales = 0.09 * CompPrice - 0.091 * Price + 4.862 * Good + 1.812 * Medium

Ее параметры можно интерпретировать следующим образом:

compprice (цена конкурента): Коэффициент перед этой переменной равен 0.09. Это означает, что при увеличении цены конкурента на единицу, продажи автокресел в данном магазине увеличиваются примерно на 0.09 единиц.

Price (цена компании): Коэффициент перед этой переменной равен -0.091. Это указывает на то, что увеличение цены компании на автокресла на единицу приведет к уменьшению продаж на приблизительно 0.091 единицы.


Качество стеллажа для размещения автокресел влияет на их продажи: продажи кресел на хороших стеллажах были выше на 3005 штук, а на плохих были ниже на 1812 штук (относительно среднего качества стеллажа).






